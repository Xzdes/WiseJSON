// test/db-advanced-scenarios.js

const path = require('path');
const fs = require('fs/promises'); // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–º–∏—Å—ã –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π fs
const assert = require('assert');
const WiseJSON = require('../wise-json/index.js');
const { cleanupExpiredDocs } = require('../wise-json/collection/ttl.js'); // –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
const { getWalPath, initializeWal, appendWalEntry, readWal } = require('../wise-json/wal-manager.js');
const { loadLatestCheckpoint, cleanupOldCheckpoints } = require('../wise-json/checkpoint-manager.js');

const DB_ROOT_PATH = path.resolve(__dirname, 'db-advanced-test-data');
const COLLECTION_NAME = 'advanced_tests_col';

async function cleanUpDbDirectory(dbPath) {
    try {
        const exists = await fs.stat(dbPath).then(() => true).catch(() => false);
        if (exists) {
            await fs.rm(dbPath, { recursive: true, force: true });
            // console.log(`[Test Cleanup] Directory ${dbPath} removed.`);
        }
    } catch (error) {
        // –ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ—Ç, fs.rm –≤—ã–±—Ä–æ—Å–∏—Ç –æ—à–∏–±–∫—É, —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –∏ –º–æ–∂–Ω–æ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å
        if (error.code !== 'ENOENT') {
            console.error(`[Test Cleanup] Error removing directory ${dbPath}:`, error);
        }
    }
}

async function sleep(ms) {
    return new Promise(res => setTimeout(res, ms));
}

async function testTtlEdgeCases() {
    console.log('  --- Running TTL Edge Cases Test ---');
    const dbPath = path.join(DB_ROOT_PATH, 'ttl_edge');
    await cleanUpDbDirectory(dbPath);

    const db = new WiseJSON(dbPath, { ttlCleanupIntervalMs: 20000 }); // –£–≤–µ–ª–∏—á–∏–º –∏–Ω—Ç–µ—Ä–≤–∞–ª, —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª —Ç–µ—Å—Ç—É
    await db.init();
    const col = await db.collection(COLLECTION_NAME);
    await col.initPromise;

    const now = Date.now();
    const createdAtISO = new Date(now).toISOString();

    // –í—Å—Ç–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    await col.insert({ _id: 'expired_past', data: 'past', expireAt: now - 10000 }); // –ò—Å—Ç–µ–∫—à–∏–π
    await col.insert({ _id: 'invalid_expire', data: 'invalid', expireAt: 'not-a-date' }); // –ù–µ–≤–∞–ª–∏–¥–Ω–∞—è –¥–∞—Ç–∞, –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è
    await col.insert({ _id: 'ttl_zero', data: 'zero_ttl', ttl: 0, createdAt: new Date(now - 1).toISOString() }); // TTL 0, –¥–æ–ª–∂–µ–Ω –∏—Å—Ç–µ—á—å
    await col.insert({ _id: 'ttl_short', data: 'short_ttl', ttl: 200, createdAt: createdAtISO }); // –ö–æ—Ä–æ—Ç–∫–∏–π TTL
    await col.insert({ _id: 'normal_doc', data: 'normal' }); // –û–±—ã—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç, –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è
    await col.insert({ _id: 'null_expire', data: 'null_expire', expireAt: null }); // expireAt: null, –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è
    await col.insert({ _id: 'undefined_ttl', data: 'undefined_ttl', ttl: undefined, createdAt: createdAtISO }); // ttl: undefined, –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è


    // –ü—Ä–æ–≤–µ—Ä—è–µ–º col.documents.size –Ω–∞–ø—Ä—è–º—É—é –¥–æ –ª—é–±–æ–≥–æ cleanup'–∞
    assert.strictEqual(col.documents.size, 7, 'Initial raw document count in map should be 7');

    // –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤ col.count() –≤—ã–∑–æ–≤–µ—Ç cleanupExpiredDocs –≤–Ω—É—Ç—Ä–∏ —Å–µ–±—è
    // –û–∂–∏–¥–∞–µ–º:
    // - 'expired_past' —É–¥–∞–ª–µ–Ω
    // - 'ttl_zero' —É–¥–∞–ª–µ–Ω
    // - 'invalid_expire' –æ—Å—Ç–∞–ª—Å—è (–∏–∑-–∑–∞ –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–∏ isAlive)
    // - 'ttl_short' –æ—Å—Ç–∞–ª—Å—è (–µ—â–µ –Ω–µ –∏—Å—Ç–µ–∫)
    // - 'normal_doc' –æ—Å—Ç–∞–ª—Å—è
    // - 'null_expire' –æ—Å—Ç–∞–ª—Å—è
    // - 'undefined_ttl' –æ—Å—Ç–∞–ª—Å—è
    // –ò—Ç–æ–≥–æ: 7 - 2 = 5
    assert.strictEqual(await col.count(), 5, 'Count after first cleanup (expired_past, ttl_zero removed)');

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–æ–∫—É–º–µ–Ω—Ç—ã
    let docInvalid = await col.getById('invalid_expire');
    assert.ok(docInvalid, 'Document with invalid expireAt should remain after first count');
    let docShort = await col.getById('ttl_short');
    assert.ok(docShort, 'Document with short TTL should still be there');
    let docNormal = await col.getById('normal_doc');
    assert.ok(docNormal, 'Normal document should be there');
    let docNullExpire = await col.getById('null_expire');
    assert.ok(docNullExpire, 'Document with null expireAt should remain');
    let docUndefinedTtl = await col.getById('undefined_ttl');
    assert.ok(docUndefinedTtl, 'Document with undefined ttl should remain');

    // –ñ–¥–µ–º, –ø–æ–∫–∞ 'ttl_short' –∏—Å—Ç–µ—á–µ—Ç
    await sleep(300); // 200ms TTL + –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å

    // –Ø–≤–Ω—ã–π cleanup –¥–ª—è —Ç–µ—Å—Ç–∞ (—Ç–∞–π–º–µ—Ä TTL –º–æ–∂–µ—Ç —Å—Ä–∞–±–æ—Ç–∞—Ç—å, –∞ –º–æ–∂–µ—Ç –∏ –Ω–µ—Ç, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏ setTimeout)
    const removedCount = cleanupExpiredDocs(col.documents, col._indexManager);
    // console.log(`[TTL Test] Docs removed by explicit cleanup: ${removedCount}`); // –û–∂–∏–¥–∞–µ–º 1 (ttl_short)

    // –¢–µ–ø–µ—Ä—å 'ttl_short' –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–¥–∞–ª–µ–Ω.
    // –û—Å—Ç–∞—é—Ç—Å—è: 'invalid_expire', 'normal_doc', 'null_expire', 'undefined_ttl'
    // –ò—Ç–æ–≥–æ: 5 - 1 = 4
    assert.strictEqual(await col.count(), 4, 'Final count after short TTL expired and explicit cleanup');

    // –§–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    const docPast = await col.getById('expired_past');
    assert.strictEqual(docPast, null, 'Document with past expireAt should be removed');

    docInvalid = await col.getById('invalid_expire');
    assert.ok(docInvalid, 'Document with invalid expireAt should remain');
    assert.strictEqual(docInvalid.data, 'invalid', 'Invalid expireAt data check');

    const docTtlZero = await col.getById('ttl_zero');
    assert.strictEqual(docTtlZero, null, 'Document with ttl: 0 should be removed');

    const docTtlShortAfterWait = await col.getById('ttl_short');
    assert.strictEqual(docTtlShortAfterWait, null, 'Document with short ttl should be removed after wait');
    
    docNormal = await col.getById('normal_doc');
    assert.ok(docNormal, 'Normal document should still be there');
    
    docNullExpire = await col.getById('null_expire');
    assert.ok(docNullExpire, 'Document with null expireAt should still be there after all cleanups');

    docUndefinedTtl = await col.getById('undefined_ttl');
    assert.ok(docUndefinedTtl, 'Document with undefined ttl should still be there after all cleanups');

    await db.close();
    await cleanUpDbDirectory(dbPath);
    console.log('  --- TTL Edge Cases Test PASSED ---');
}

async function testCorruptedWalRecovery() {
    console.log('  --- Running Corrupted WAL Recovery Test ---');
    const dbPath = path.join(DB_ROOT_PATH, 'wal_corrupt');
    await cleanUpDbDirectory(dbPath);

    const colDir = path.join(dbPath, COLLECTION_NAME);
    await fs.mkdir(colDir, { recursive: true });

    const walPath = getWalPath(colDir, COLLECTION_NAME);
    await initializeWal(walPath, colDir); // –°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π WAL

    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –∑–∞–ø–∏—Å–∏
    await appendWalEntry(walPath, { op: 'INSERT', doc: { _id: 'doc1', name: 'Valid Doc 1', value: 10 } });
    await appendWalEntry(walPath, { op: 'INSERT', doc: { _id: 'doc2', name: 'Valid Doc 2', value: 20 } });
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –±–∏—Ç—É—é —Å—Ç—Ä–æ–∫—É
    await fs.appendFile(walPath, 'this is not a valid json line that will be skipped\n', 'utf8');
    // –ï—â–µ –æ–¥–Ω–∞ –≤–∞–ª–∏–¥–Ω–∞—è –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ –±–∏—Ç–æ–π
    await appendWalEntry(walPath, { op: 'INSERT', doc: { _id: 'doc3', name: 'Valid Doc 3 After Corrupt', value: 30 } });
    // –ó–∞–ø–∏—Å—å –Ω–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    await appendWalEntry(walPath, { op: 'UPDATE', id: 'doc1', data: { name: 'Updated Doc 1', value: 15 } });
    // –ó–∞–ø–∏—Å—å –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
    await appendWalEntry(walPath, { op: 'REMOVE', id: 'doc2' });


    // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î, –æ–Ω–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ—á–∏—Ç–∞—Ç—å WAL
    // –ü–µ—Ä–µ–¥–∞–µ–º –æ–ø—Ü–∏—é recover, —á—Ç–æ–±—ã wal-manager –Ω–µ –ø–∞–¥–∞–ª –Ω–∞ –æ—à–∏–±–∫–µ, –∞ –ø—Ä–æ–ø—É—Å–∫–∞–ª –±–∏—Ç—É—é —Å—Ç—Ä–æ–∫—É
    const db = new WiseJSON(dbPath, { walReadOptions: { recover: true, strict: false } });
    await db.init(); // –≠—Ç–æ—Ç init –Ω–µ—è–≤–Ω–æ –≤—ã–∑–æ–≤–µ—Ç col.init, –µ—Å–ª–∏ –º—ã –ø–æ—Ç–æ–º –≤—ã–∑–æ–≤–µ–º db.collection
    
    const col = await db.collection(COLLECTION_NAME);
    await col.initPromise; // –≠—Ç–æ –≤—ã–∑–æ–≤–µ—Ç —á—Ç–µ–Ω–∏–µ WAL —Å –æ–ø—Ü–∏—è–º–∏ –∏–∑ db.options

    // –û–∂–∏–¥–∞–µ–º:
    // doc1 - –≤—Å—Ç–∞–≤–ª–µ–Ω –∏ –æ–±–Ω–æ–≤–ª–µ–Ω
    // doc2 - –≤—Å—Ç–∞–≤–ª–µ–Ω –∏ —É–¥–∞–ª–µ–Ω
    // doc3 - –≤—Å—Ç–∞–≤–ª–µ–Ω
    // –ò—Ç–æ–≥–æ 2 –¥–æ–∫—É–º–µ–Ω—Ç–∞ (doc1, doc3)
    const count = await col.count();
    assert.strictEqual(count, 2, 'Should recover 2 documents after WAL processing (doc1 updated, doc2 removed, doc3 inserted)');

    const doc1 = await col.getById('doc1');
    assert.ok(doc1, 'doc1 should be recovered');
    assert.strictEqual(doc1.name, 'Updated Doc 1', 'doc1 should be updated');
    assert.strictEqual(doc1.value, 15, 'doc1 value should be updated');

    const doc2 = await col.getById('doc2');
    assert.strictEqual(doc2, null, 'doc2 should be removed');

    const doc3 = await col.getById('doc3');
    assert.ok(doc3, 'doc3 (after corruption) should be recovered');
    assert.strictEqual(doc3.name, 'Valid Doc 3 After Corrupt', 'doc3 name check');


    // –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ WAL –±—ã–ª –ø—Ä–æ—á–∏—Ç–∞–Ω —Å –æ–ø—Ü–∏–µ–π recover (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å warning –≤ –∫–æ–Ω—Å–æ–ª–∏)
    // –≠—Ç–æ —Å–ª–æ–∂–Ω–µ–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±–µ–∑ –º–æ–∫–∏–Ω–≥–∞ console.warn,
    // –Ω–æ –º—ã –æ–∂–∏–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

    await db.close();
    await cleanUpDbDirectory(dbPath);
    console.log('  --- Corrupted WAL Recovery Test PASSED ---');
}

async function testIndexEdgeCases() {
    console.log('  --- Running Index Edge Cases Test ---');
    const dbPath = path.join(DB_ROOT_PATH, 'index_edge');
    await cleanUpDbDirectory(dbPath);

    const db = new WiseJSON(dbPath);
    await db.init();
    const col = await db.collection(COLLECTION_NAME);
    await col.initPromise;

    // 1. –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    await col.createIndex('email', { unique: false }); // –ù–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –¥–ª—è –Ω–∞—á–∞–ª–∞
    let indexes = await col.getIndexes();
    assert.strictEqual(indexes.length, 1, 'Index should be created');
    assert.strictEqual(indexes[0].fieldName, 'email', 'Correct index fieldName');
    assert.strictEqual(indexes[0].type, 'standard', 'Index type should be standard');

    // 2. –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å (–¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—à–∏–±–∫–∞)
    let errorThrown = false;
    try {
        await col.createIndex('email'); // –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å —Ç–∞–∫–æ–π –∂–µ
    } catch (e) {
        assert.ok(e.message.includes('already exists') || e.message.includes('—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç'), 'Error for duplicate index definition');
        errorThrown = true;
    }
    assert.ok(errorThrown, 'Should throw error when creating an existing index definition');
    indexes = await col.getIndexes();
    assert.strictEqual(indexes.length, 1, 'Index count should remain 1 after failed creation');

    // 3. –£–¥–∞–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
    await col.dropIndex('email');
    indexes = await col.getIndexes();
    assert.strictEqual(indexes.length, 0, 'Index should be dropped');

    // 4. –ü–æ–ø—ã—Ç–∫–∞ —É–¥–∞–ª–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—à–∏–±–∫–∏, –ø—Ä–æ—Å—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç)
    await col.dropIndex('non_existent_field');
    indexes = await col.getIndexes();
    assert.strictEqual(indexes.length, 0, 'Dropping non-existent index should not change index list');

    // 5. –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    await col.createIndex('username', { unique: true });
    indexes = await col.getIndexes();
    assert.strictEqual(indexes.length, 1, 'Unique index should be created');
    assert.strictEqual(indexes[0].fieldName, 'username', 'Correct unique index fieldName');
    assert.strictEqual(indexes[0].type, 'unique', 'Index type should be unique');

    await db.close();
    await cleanUpDbDirectory(dbPath);
    console.log('  --- Index Edge Cases Test PASSED ---');
}

async function testEmptyDbOperations() {
    console.log('  --- Running Empty DB Operations Test ---');
    const dbPath = path.join(DB_ROOT_PATH, 'empty_db_ops'); // –ò–∑–º–µ–Ω–∏–ª –∏–º—è, —á—Ç–æ–±—ã –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –µ—Å–ª–∏ cleanup –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç
    await cleanUpDbDirectory(dbPath);

    const db = new WiseJSON(dbPath);
    await db.init(); // –í–∞–∂–Ω–æ, —á—Ç–æ–±—ã —Å–∞–º–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è dbPath –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç

    // 1. getCollectionNames –¥–ª—è –ø—É—Å—Ç–æ–π –ë–î (dbPath —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –Ω–æ –≤ –Ω–µ–π –Ω–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∫–æ–ª–ª–µ–∫—Ü–∏–π)
    const names = await db.getCollectionNames();
    assert.deepStrictEqual(names, [], 'getCollectionNames on empty DB directory should return empty array');

    // 2. –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–∏
    // WiseJSON —Å–æ–∑–¥–∞—Å—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è 'non_existent_col' –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏
    const col = await db.collection('non_existent_col');
    await col.initPromise;

    const colPath = path.join(dbPath, 'non_existent_col');
    const colDirExists = await fs.stat(colPath).then(stat => stat.isDirectory()).catch(() => false);
    assert.ok(colDirExists, 'Directory for new collection should be created');

    assert.strictEqual(await col.count(), 0, 'Count on new empty collection should be 0');
    const doc = await col.getById('any_id');
    assert.strictEqual(doc, null, 'getById on empty collection should return null');

    // 3. –°–æ–∑–¥–∞–µ–º –µ—â–µ –æ–¥–Ω—É –∫–æ–ª–ª–µ–∫—Ü–∏—é, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å getCollectionNames
    const col2 = await db.collection('another_col');
    await col2.initPromise; // –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ
    await col2.insert({_id: 'test'}); // –î–æ–±–∞–≤–∏–º –¥–æ–∫—É–º–µ–Ω—Ç, —á—Ç–æ–±—ã –∫–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –±—ã–ª–∞ –ø—É—Å—Ç–æ–π –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ
    await col2.flushToDisk(); // –°–æ—Ö—Ä–∞–Ω–∏–º —á–µ–∫–ø–æ–∏–Ω—Ç, —á—Ç–æ–±—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ç–æ—á–Ω–æ –±—ã–ª–∞ "–∑–∞–ø–æ–ª–Ω–µ–Ω–∞"

    const updatedNames = (await db.getCollectionNames()).sort(); // –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    assert.deepStrictEqual(updatedNames, ['another_col', 'non_existent_col'].sort(), 'getCollectionNames should list newly created collections');

    await db.close();
    await cleanUpDbDirectory(dbPath);
    console.log('  --- Empty DB Operations Test PASSED ---');
}

async function testSegmentedCheckpointCleanup() {
    console.log('  --- Running Segmented Checkpoint Cleanup Test ---');
    const dbPath = path.join(DB_ROOT_PATH, 'checkpoint_cleanup_seg'); // –ò–∑–º–µ–Ω–∏–ª –∏–º—è
    await cleanUpDbDirectory(dbPath);

    const dbOptions = {
        maxSegmentSizeBytes: 50,  // –û—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞ (–º–µ–Ω—å—à–µ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞)
        checkpointsToKeep: 2,
        checkpointIntervalMs: 5 * 60 * 1000, // –ë–æ–ª—å—à–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª, —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤—Ä—É—á–Ω—É—é
    };
    const db = new WiseJSON(dbPath, dbOptions);
    await db.init();
    const col = await db.collection(COLLECTION_NAME);
    await col.initPromise;

    // –í—Å—Ç–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    for (let i = 0; i < 5; i++) { // –ú–µ–Ω—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –Ω–æ –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–ø–∞—Å—Ç—å –≤ —Ä–∞–∑–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑-–∑–∞ —Ä–∞–∑–º–µ—Ä–∞
        await col.insert({ _id: `doc_seg_${i}`, text: `Document segment content part ${i} with enough text to exceed segment size potentially.` });
    }

    // –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –≤—Ä—É—á–Ω—É—é
    // –ö–∞–∂–¥—ã–π flushToDisk —Å–æ–∑–¥–∞–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç –∏ –≤—ã–∑—ã–≤–∞–µ—Ç compactWal,
    // –∞ close —É –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Ç–∞–∫–∂–µ –≤—ã–∑—ã–≤–∞–µ—Ç flushToDisk.
    // cleanupOldCheckpoints –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ flushToDisk –Ω–µ—è–≤–Ω–æ –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–æ–≤–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞.

    await col.flushToDisk(); // Checkpoint 1 (—Å–æ–∑–¥–∞–Ω, cleanup –µ—â–µ –Ω–µ—á–µ–≥–æ —É–¥–∞–ª—è—Ç—å –∏–ª–∏ —É–¥–∞–ª–∏—Ç 0)
    await sleep(20); // –†–∞–∑–Ω—ã–µ timestamp
    await col.insert({ _id: 'extra_doc_cp2', text: 'Another doc for checkpoint 2' });
    await col.flushToDisk(); // Checkpoint 2 (—Å–æ–∑–¥–∞–Ω, cleanup –º–æ–∂–µ—Ç —É–¥–∞–ª–∏—Ç—å —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π, –µ—Å–ª–∏ –∏—Ö > checkpointsToKeep)

    await sleep(20);
    await col.insert({ _id: 'extra_doc_cp3', text: 'Yet another doc for checkpoint 3' });
    await col.flushToDisk(); // Checkpoint 3 (—Å–æ–∑–¥–∞–Ω, —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö (–µ—Å–ª–∏ –∏—Ö –±—ã–ª–æ >2) –¥–æ–ª–∂–µ–Ω —É–¥–∞–ª–∏—Ç—å—Å—è)

    await sleep(20);
    await col.insert({ _id: 'extra_doc_cp4', text: 'Final doc for checkpoint 4' });
    await col.flushToDisk(); // Checkpoint 4 (—Å–æ–∑–¥–∞–Ω, ...)

    const checkpointsDir = path.join(dbPath, COLLECTION_NAME, '_checkpoints');
    let files = [];
    try {
        files = await fs.readdir(checkpointsDir);
    } catch (e) {
        // –ï—Å–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–µ—Ç, —ç—Ç–æ —Ç–æ–∂–µ –ø—Ä–æ–≤–∞–ª –¥–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        assert.fail(`Checkpoints directory not found: ${checkpointsDir}`);
    }

    const metaFiles = files.filter(f => f.startsWith(`checkpoint_meta_${COLLECTION_NAME}_`) && f.endsWith('.json'));
    const dataFiles = files.filter(f => f.startsWith(`checkpoint_data_${COLLECTION_NAME}_`) && f.endsWith('.json'));

    assert.strictEqual(metaFiles.length, dbOptions.checkpointsToKeep, `Should keep ${dbOptions.checkpointsToKeep} meta checkpoint files. Found: ${metaFiles.join(', ')}`);

    const keptTimestamps = new Set(
        metaFiles.map(f => {
            const match = f.match(new RegExp(`^checkpoint_meta_${COLLECTION_NAME}_(.+)\\.json$`));
            return match ? match[1] : null;
        }).filter(Boolean)
    );
    assert.strictEqual(keptTimestamps.size, dbOptions.checkpointsToKeep, 'Number of unique timestamps in kept meta files should match checkpointsToKeep');

    for (const dataFile of dataFiles) {
        const match = dataFile.match(new RegExp(`^checkpoint_data_${COLLECTION_NAME}_(.+)_seg\\d+\\.json$`));
        const dataTimestamp = match ? match[1] : null;
        assert.ok(dataTimestamp, `Could not parse timestamp from data file: ${dataFile}`);
        assert.ok(keptTimestamps.has(dataTimestamp), `Data segment ${dataFile} (ts: ${dataTimestamp}) should belong to a kept checkpoint. Kept TS: ${Array.from(keptTimestamps).join(', ')}`);
    }

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω data-—Å–µ–≥–º–µ–Ω—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ meta-—Ñ–∞–π–ª–∞
    const dataFileTimestamps = new Set(
        dataFiles.map(f => {
            const match = f.match(new RegExp(`^checkpoint_data_${COLLECTION_NAME}_(.+)_seg\\d+\\.json$`));
            return match ? match[1] : null;
        }).filter(Boolean)
    );
    assert.deepStrictEqual(dataFileTimestamps, keptTimestamps, 'Timestamps of data segments should match timestamps of kept meta files.');
    assert.ok(dataFiles.length >= dbOptions.checkpointsToKeep, 'Should have at least as many data files as meta files kept');

    await db.close();
    await cleanUpDbDirectory(dbPath);
    console.log('  --- Segmented Checkpoint Cleanup Test PASSED ---');
}


async function main() {
    console.log('=== ADVANCED SCENARIOS DB TEST START ===');
    try {
        await fs.mkdir(DB_ROOT_PATH, { recursive: true });
    } catch (e) { /* –º–æ–∂–µ—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å, —ç—Ç–æ –æ–∫ */ }

    try {
        await testTtlEdgeCases();
        await testCorruptedWalRecovery();
        await testIndexEdgeCases();
        await testEmptyDbOperations();
        await testSegmentedCheckpointCleanup();

        console.log('=== ADVANCED SCENARIOS DB TEST PASSED SUCCESSFULLY ===');
    } catch (error) {
        console.error('\nüî• ADVANCED SCENARIOS TEST FAILED:', error);
        // –ù–µ —É–¥–∞–ª—è–µ–º DB_ROOT_PATH –µ—Å–ª–∏ —Ç–µ—Å—Ç—ã —É–ø–∞–ª–∏, –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        console.error(`\n‚ùó Test data was NOT removed for debugging: ${DB_ROOT_PATH}`);
        process.exit(1);
    } finally {
        // –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ–π –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ç–µ—Å—Ç–æ–≤, –¢–û–õ–¨–ö–û –ï–°–õ–ò –í–°–ï –ü–†–û–®–õ–û –£–°–ü–ï–®–ù–û
        // –ï—Å–ª–∏ —Ç–µ—Å—Ç—ã —É–ø–∞–ª–∏, —ç—Ç–æ—Ç –±–ª–æ–∫ –Ω–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –∏–∑-–∑–∞ process.exit(1) –≤ catch
        // –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –≤—Å–µ–≥–¥–∞ —á–∏—Å—Ç–∏—Ç—å, –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å process.exit(1) –∏ –ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ cleanUpDbDirectory —Å—é–¥–∞.
        // –û–¥–Ω–∞–∫–æ, –¥–ª—è CI –ª—É—á—à–µ –æ—Å—Ç–∞–≤–ª—è—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏.
        if (process.exitCode !== 1) { // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –±—ã–ª–æ –ª–∏ –æ—à–∏–±–∫–∏
             // await cleanUpDbDirectory(DB_ROOT_PATH);
             // console.log('[Test Main] Final cleanup of DB_ROOT_PATH skipped for now.');
        }
    }
}

// –ó–∞–ø—É—Å–∫–∞–µ–º main –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ –Ω–∞ —Å–∞–º–æ–º –≤–µ—Ä—Ö–Ω–µ–º —É—Ä–æ–≤–Ω–µ
main().catch(err => {
    console.error('\nüî• UNHANDLED ERROR IN TEST RUNNER (main function level):', err);
    console.error(`\n‚ùó Test data was NOT removed for debugging: ${DB_ROOT_PATH}`);
    process.exit(1);
});